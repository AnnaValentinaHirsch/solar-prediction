{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f502f1-ed6e-453a-852b-dd8e605c1799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# spectral analysis\n",
    "from scipy import signal\n",
    "from scipy.signal import periodogram as periodogram_f\n",
    "from scipy.fft import fftfreq, fftshift\n",
    "from scipy.fft import fft, ifft, fft2, ifft2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b576bdd-dde5-4cf9-9ccc-ce9ae674c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pandas 2.0, one could use date_format='%Y-%m-%d %H:%M:%S%z', but that's not yet available on Arch Linux\n",
    "solar_ts=pd.read_csv(\"data/energy_charts.csv\", sep=\",\", header=0)#date_format='%Y-%m-%d %H:%M:%S%z')#parse_dates={\"date\": [\"Datum\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(solar_ts['Datum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531cc0d3-b869-44b4-9afb-3d1cf5e9fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_ts['Datum']=pd.to_datetime(solar_ts['Datum'], format='%Y-%m-%dT%H:%M%z', utc=True)\n",
    "solar_ts=solar_ts.set_index(keys=\"Datum\",drop=True)\n",
    "solar_ts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e15e8b-a040-4f18-8f7f-2355d45143df",
   "metadata": {},
   "outputs": [],
   "source": [
    "adfresult = adfuller(solar_ts[2:30000])\n",
    "print(adfresult[0])\n",
    "print(adfresult[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a0a4a7-b3e5-4c89-8a15-f4fe4d04dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://stackoverflow.com/questions/30379789/plot-pandas-data-frame-with-year-over-year-data\n",
    "pv = pd.pivot_table(solar_ts, index=solar_ts.index.dayofyear, columns=solar_ts.index.year,\n",
    "                    values='Leistung', aggfunc='sum')\n",
    "pv.plot(cmap=\"Grays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a7dba-0fcc-4035-b780-71ebc35ad6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://stackoverflow.com/questions/30379789/plot-pandas-data-frame-with-year-over-year-data\n",
    "pv = pd.pivot_table(solar_ts, index=solar_ts.index.month, columns=solar_ts.index.year,\n",
    "                    values='Leistung', aggfunc='sum')\n",
    "pv.plot(cmap=\"Grays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379a931-52ec-4f08-9637-b0ca016cac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of a gap in the data\n",
    "# TODO: Also, there is duplicate data here that pandas duplicated-function will not find...?\n",
    "solar_ts.index[5660:5680]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd59dcef-6826-4a52-9727-5109d6e44eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(solar_ts.index.duplicated()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf15e79e-23c9-46e0-bc0d-c2548153c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.Series(solar_ts.index[5660:5680]).diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8705cd7-e2e5-4167-bcea-a6c0b9f4507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those values need imputation!\n",
    "pd.date_range(solar_ts.index.min(), solar_ts.index.max(), freq='15Min').difference(solar_ts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7261491-58cb-4e1c-96b5-e436eaa70ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This add NaN as value for the missing indices, we can impute this later.\n",
    "solar_ts = solar_ts.resample(\"15Min\").first()\n",
    "# As only a few values need imputation, so the choice of the imputation algorithm does not matter much.\n",
    "solar_ts = solar_ts.interpolate(method=\"time\")\n",
    "# Only now can we infer a frequency.\n",
    "solar_ts=solar_ts.asfreq(pd.infer_freq(solar_ts.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f95b7c-7088-4f79-90a0-9842e9b2111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are no duplicated dates, good!\n",
    "# (Although, a bit questionable, see above)\n",
    "np.count_nonzero(solar_ts.index.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98ea80c-b9a6-4606-b896-74353461c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_ts=solar_ts.asfreq(pd.infer_freq(solar_ts.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31293d6a-c751-4c2a-81ab-cb7f3607a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_ts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1fc4d2-697a-46e1-8334-6f33afebf42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_ts_series = solar_ts.Leistung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d5c34-5c75-473a-ab94-ff61c9886873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "avg, dev = solar_ts_series.mean(), solar_ts_series.std()\n",
    "solar_ts_series = (solar_ts_series - avg)/dev\n",
    "solar_ts_series.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21fa836-fe31-41ff-a6aa-d316bb924aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove trend (TODO: compare with the approach in the Fourier series video, where they also detrend?)\n",
    "solar_ts_series = solar_ts_series.diff().dropna()\n",
    "solar_ts_series.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c679ad7c-345e-48fc-9494-a16aed55b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider taking another difference: solar_ts_series = solar_ts_series.diff().dropna()\n",
    "# solar_ts_series.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f9996-9027-4563-b643-44ffec5fd885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove increasing volatility - or (TODO: use a (G)ARCH here).\n",
    "annual_volatility = solar_ts_series.groupby(solar_ts_series.index.year).std()\n",
    "annual_vol_per_day = solar_ts_series.index.map(lambda d: annual_volatility.loc[d.year])\n",
    "solar_ts_series_corrected_variance = solar_ts_series/annual_vol_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d177d73-7d2c-48cc-92d6-f51f05027512",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b68af-4702-4f76-92b6-ddce38ff8734",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_vol_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1de49e-6a34-4fcc-a69d-bc45b911a217",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_ts_series_corrected_variance.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b21932-91ff-4b0a-afa4-149e15168810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ritvik takes monthly means here\n",
    "# why not take dayofyear?\n",
    "monthly_mean = solar_ts_series_corrected_variance.groupby(solar_ts_series_corrected_variance.index.month).mean()\n",
    "monthly_mean_per_day = solar_ts_series_corrected_variance.index.map(lambda d: monthly_mean.loc[d.month])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895cfec4-0707-458f-8049-c302c45e8b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_ts_series_corrected_variance= solar_ts_series_corrected_variance - monthly_mean_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e34a52-00b7-47f0-baef-cc93756608e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_ts_series_corrected_variance.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41265201-fad2-46bc-a641-6029a9103b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only take the first few samples as my RAM explodes otherwise\n",
    "adfresult = adfuller(solar_ts_series_corrected_variance[3:30000])\n",
    "print(adfresult[0])\n",
    "print(adfresult[1])\n",
    "adfresult = adfuller(solar_ts_series_corrected_variance[120000:150000])\n",
    "print(adfresult[0])\n",
    "print(adfresult[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f25a6a4-0f86-4870-8c5c-45759adc4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_ts_series_corrected_variance=solar_ts_series_corrected_variance[~np.isnan(solar_ts_series_corrected_variance)]\n",
    "solar_ts_series_corrected_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c81ebe2-0a6e-4515-82d4-70eefb852582",
   "metadata": {},
   "source": [
    "# some spectral analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b1d88-85b7-4e91-b38b-e2f6d983973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts has period 15 minutes\n",
    "dt = 15*60\n",
    "rate = 1/dt\n",
    "periodogram = np.abs(fft(np.asarray(solar_ts_series_corrected_variance)))**2*dt/(len(solar_ts_series_corrected_variance))\n",
    "frequencies = fftfreq(len(solar_ts_series_corrected_variance), d=1/rate)\n",
    "frequencies\n",
    "plt.plot(fftshift(frequencies), fftshift(periodogram))\n",
    "plt.xlim(-0.00002, 0.0001)\n",
    "plt.ylim(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333bef6c-8f1c-401c-8444-9036e00ba307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks (and should be!) similar to the \"manual\" calculation above.\n",
    "# Note that in the manual calculation, we get a symmetric graph. That's to be expected (check out the videos).\n",
    "frequencies, periodogram = periodogram_f(np.asarray(solar_ts_series_corrected_variance), fs=rate, window=\"hamming\")\n",
    "plt.plot(fftshift(frequencies), fftshift(periodogram))\n",
    "plt.xlim(-0.00002, 0.0001)\n",
    "plt.ylim(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd7026b-102a-4837-9351-eb35f1071592",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodogram_as_series = pd.Series(fftshift(periodogram), index=fftshift(frequencies))\n",
    "periodogram_as_series = periodogram_as_series[periodogram_as_series.index > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c7556d-471b-4638-8f9a-f94ec2960f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert index from frequencies to periods and convert the periods to hours\n",
    "# TODO: is the calculation to hours correct (note that  we already specified the sampling rate during the fft!)?\n",
    "periodogram_as_series.index = (1/periodogram_as_series.index)/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a6874-1b87-4f91-91c1-fce2a4a299f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(periodogram_as_series)\n",
    "plt.xlim(0,100000/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8585a74b-8674-4688-8480-0fa50f38f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use SARIMA, => detrend and remove saisonality\n",
    "# Take a look the the residuals\n",
    "# is the model good?\n",
    "# Then, the residuals have no (p)ACF\n",
    "# check QQ - WN has no heavy tails :)\n",
    "# also consider: https://www.youtube.com/watch?v=4zV-ZyQHl7s\n",
    "\n",
    "# TODO: decompose + fit SARIMA model\n",
    "# before: continue with denoising :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9996f-2114-465c-bf86-74eb46a108fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yet another way to calculate the FFT, from the \"denoising\" video.\n",
    "# However, apparently, the signal is now dampened. The frequencies themselves are correct, though\n",
    "# Note how damped the signal appears visually already although the y-scale is really small!\n",
    "n = len(solar_ts_series_corrected_variance)\n",
    "fhat = np.fft.fft(solar_ts_series_corrected_variance, n)\n",
    "PSD = fhat*np.conj(fhat)/n\n",
    "freq = (1/(dt*n))*np.arange(n)\n",
    "L= np.arange(1, np.floor(n/2), dtype=\"int\")\n",
    "plt.plot(freq[L], PSD[L])\n",
    "plt.xlim(-0.00002, 0.0001)\n",
    "plt.ylim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b75c6bf-4c2e-4329-ab46-7911dc4fbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now decide on the frequencies to cut off.\n",
    "plt.plot(freq, PSD)\n",
    "plt.ylim(1e-2,1e5)\n",
    "plt.axhline(y=1e0, color=\"r\")\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fce48a-95e8-463b-a1dc-f6458d7de9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll only retain frequencies with powers above the red line in the graph above.\n",
    "# I chose it such that almost all high-power frequencies are retained. We get some noisy frequencies in (at the tails) but the majority is filtered.\n",
    "indices = PSD > 1e0\n",
    "# Filter and reconstruct the signal on the retained frequencies (reverse fourier transform)\n",
    "PSDclean = PSD*indices\n",
    "fhat = indices*fhat\n",
    "ffilt = np.fft.ifft(fhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad1312d-823b-4b7f-8614-ab59e412a65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small sanity check: our new spectrum looks like this: nice, huh?\n",
    "plt.plot(PSDclean)\n",
    "plt.ylim(1e-2,1e5)\n",
    "plt.axhline(y=1e0, color=\"r\")\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6acb68-7925-4894-8a56-b0c4630adfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_ts_series_corrected_variance.plot()\n",
    "plt.ylim(-4,4)\n",
    "pd.Series(ffilt, solar_ts_series_corrected_variance.index).plot()\n",
    "plt.ylim(-4,4)\n",
    "plt.legend([\"original\", \"after fft\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a15e8",
   "metadata": {},
   "source": [
    "# Model Class, Backtesting, Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1921a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesPredictionModel():\n",
    "    \"\"\"\n",
    "    Time series prediction model implementation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        model_name : class\n",
    "            Choice of regressor\n",
    "        model_params : dict\n",
    "            Definition of model specific tuning parameters\n",
    "    \n",
    "    Functions\n",
    "    ----------\n",
    "        init: Initialize model with given parameters\n",
    "        train : Train chosen model\n",
    "        forcast : Apply trained model to prediction period and generate forecast DataFrame\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, \n",
    "                 model_params: dict) -> None:\n",
    "        \"\"\"Initialize a new instance of time_series_prediction_model.\"\"\"\n",
    "        self.model = model_name(**model_params) \n",
    "    \n",
    "    def train(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:\n",
    "        \"\"\"Train chosen model.\"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "    \n",
    "    def forecast(self, X_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Apply trained model to prediction period and generate forecast DataFrame.\"\"\"\n",
    "        self.X_test = X_test\n",
    "        forecast_df = pd.DataFrame(self.model.predict(self.X_test), index=self.X_test.index)\n",
    "        forecast_df.index.name = 'Datum'\n",
    "        return forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7409904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtesting with sliding window\n",
    "\n",
    "def backtesting(X_train: pd.DataFrame, y_train: pd.DataFrame,\n",
    "                X_test: pd.DataFrame, y_test: pd.DataFrame,\n",
    "                model: TimeSeriesPredictionModel, prediction_step_size: int=96):\n",
    "\n",
    "    # initializing output df\n",
    "    predictions = pd.DataFrame(index=y_test.index, columns=['Original', 'Predictions'])\n",
    "    predictions['Original'] = y_test\n",
    "\n",
    "    for i in range(0, len(X_test)-prediction_step_size, prediction_step_size):\n",
    "        end_idx = i + prediction_step_size\n",
    "        forecast_index= X_test.iloc[i:end_idx].index\n",
    "        \n",
    "        # fit model and predict\n",
    "        model.train(X_train, y_train)\n",
    "        forecast = model.forecast(X_test.iloc[i:end_idx])\n",
    "        predictions.loc[forecast_index, 'Predictions'] = forecast.to_numpy()\n",
    "    \n",
    "        print(f'Finished Forecast for {forecast_index[-1].date()}')\n",
    "\n",
    "        # delete old time window from train data\n",
    "        X_train = X_train.drop(X_train.head(prediction_step_size).index)\n",
    "        y_train = y_train.drop(y_train.head(prediction_step_size).index)\n",
    "\n",
    "        # add next time window to train data\n",
    "        X_train = pd.concat([X_train, X_test.iloc[i:end_idx]])\n",
    "        y_train = pd.concat([y_train, y_test.iloc[i:end_idx]])\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fedbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error, r2_score, root_mean_squared_error\n",
    "\n",
    "def evaluation(y_true, y_pred):\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    return mae, mape, mse, r2, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb3dda1",
   "metadata": {},
   "source": [
    "# Univariate Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed15503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e549ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation for Naive Model\n",
    "ts = solar_ts_series_corrected_variance\n",
    "ts = ts.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7018d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics import tsaplots\n",
    "\n",
    "fig = tsaplots.plot_acf(ts, lags=240)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37edad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy data preparation for TimeSeriesPredictionModel\n",
    "#TODO: LAGS überarbeiten\n",
    "\n",
    "data = pd.DataFrame(index=ts.index, columns=['25h_lag', '24h_lag', 'Original'])\n",
    "data['Original'] = ts\n",
    "data['24h_lag'] = ts.shift(96)\n",
    "data['25h_lag'] = ts.shift(100)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04cf424",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date_start = '2024-01-01 00:00+00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d0ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Data train-test split\n",
    "train_df = data[:test_date_start]\n",
    "train_df = train_df.drop(train_df.tail(1).index)\n",
    "X_train = train_df[['25h_lag', '24h_lag']]\n",
    "y_train = train_df[['Original']]\n",
    "\n",
    "test_df = data[test_date_start:]\n",
    "X_test = test_df[['25h_lag', '24h_lag']]\n",
    "y_test = test_df[['Original']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b3edf",
   "metadata": {},
   "source": [
    "# Univariate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb7ca8a",
   "metadata": {},
   "source": [
    "## Naive Model: Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6162d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving average model\n",
    "def moving_average(data: pd.DataFrame, window_size: int=4*3, shift_size: int=96):\n",
    "    moving_avg = data.rolling(window=window_size).mean()\n",
    "    shifted_moving_avg = moving_avg.shift(shift_size)\n",
    "    return(shifted_moving_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98764d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Naive Model\n",
    "naive_model = moving_average(ts)\n",
    "\n",
    "test_date_start = '2024-01-01 00:00+00:00'\n",
    "test_ts = ts[test_date_start:]\n",
    "naive_model_print = naive_model[test_date_start:]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_ts.index, test_ts, label='Original')\n",
    "plt.plot(naive_model_print.index, naive_model_print, label='Moving average', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('Naive Model v.s. Original Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Time Series')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a255bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, mape, mse, r2, rmse = evaluation(test_ts, naive_model_print)\n",
    "\n",
    "print(f'Model: Naive Moving Average \\n Mean absolute error: {mae}\\n Mean absolute percentage error: {mape} \\n Mean squared error: {mse} \\n r2_score: {r2} \\n Root mean squared error: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd2545",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc715f2",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba72cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f3a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing random forest regressor as instance of TimeSeriesPredictionModel\n",
    "rdnf = TimeSeriesPredictionModel(RandomForestRegressor, {'n_estimators': 10, 'criterion': 'squared_error', 'max_depth': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab0b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnf_pred = backtesting(X_train, y_train, X_test, y_test, rdnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bceee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnf_pred = rdnf_pred.dropna() # ausgehend vom ersten Testzeitraum werden nur vollständige Test-Perioden predicted\n",
    "rdnf_pred.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e16a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, mape, mse, r2, rmse = evaluation(rdnf_pred['Original'], rdnf_pred['Predictions'])\n",
    "\n",
    "print(f'Model: Random Forest \\n Mean absolute error: {mae}\\n Mean absolute percentage error: {mape} \\n Mean squared error: {mse} \\n r2_score: {r2} \\n Root mean squared error: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae5ffe",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11034aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b5f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Initializing CatBoost regressor as instance of TimeSeriesPredictionModel\n",
    "cboost = TimeSeriesPredictionModel(CatBoostRegressor, {'iterations': 25, 'learning_rate': 0.5, 'depth': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb82b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cboost_pred = backtesting(X_train, y_train, X_test, y_test, cboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ee7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cboost_pred = cboost_pred.dropna() # ausgehend vom ersten Testzeitraum werden nur vollständige Test-Perioden predicted\n",
    "cboost_pred.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, mape, mse, r2, rmse = evaluation(cboost_pred['Original'], cboost_pred['Predictions'])\n",
    "\n",
    "print(f'Model: CatBoost \\n Mean absolute error: {mae}\\n Mean absolute percentage error: {mape} \\n Mean squared error: {mse} \\n r2_score: {r2} \\n Root mean squared error: {rmse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
