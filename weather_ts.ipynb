{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install openmeteo-requests requests-cache retry-requests numpy pandas matplotlib torch scikit-learn scipy seaborn statsmodels seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import torch \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from retry_requests import retry\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "# from statsmodels.tsa.stattools import coint_johansen # ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load solar data\n",
    "solar_ts = pd.read_csv(\"/home/moonchild/PythonProjects/solar-prediction/data/energy_charts.csv\", sep=\",\", header=0)\n",
    "solar_ts[\"date\"] = pd.to_datetime(solar_ts[\"Datum\"], utc=True)\n",
    "solar_ts.drop(columns=[\"Datum\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Open-Meteo API client with cache and retry on error\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "# Make sure all required train variables are listed here\n",
    "# The order of variables in hourly or daily is important to assign them correctly below\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "params = {\n",
    "\t\"latitude\": 52.5244,\n",
    "\t\"longitude\": 13.4105,\n",
    "\t\"start_date\": \"2014-01-01\",\n",
    "\t\"end_date\": \"2024-05-01\",\n",
    "\t\"hourly\": [\n",
    "        \"temperature_2m\", \n",
    "        \"cloud_cover\", \n",
    "        \"shortwave_radiation\", \n",
    "        \"diffuse_radiation\", \n",
    "        \"direct_normal_irradiance\", \n",
    "        \"is_day\", \n",
    "        \"sunshine_duration\"\n",
    "        ],\n",
    "\t\"timezone\": \"Europe/Berlin\"\n",
    "}\n",
    "\n",
    "responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "# Process first location. Add a for-loop for multiple locations or weather models\n",
    "response = responses[0]\n",
    "print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "print(f\"Elevation {response.Elevation()} m asl\")\n",
    "print(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
    "print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
    "\n",
    "# Process hourly data. The order of variables needs to be the same as requested.\n",
    "hourly = response.Hourly()\n",
    "hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "hourly_cloud_cover = hourly.Variables(1).ValuesAsNumpy()\n",
    "hourly_shortwave_radiation = hourly.Variables(2).ValuesAsNumpy()\n",
    "hourly_diffuse_radiation = hourly.Variables(3).ValuesAsNumpy()\n",
    "hourly_direct_normal_irradiance = hourly.Variables(4).ValuesAsNumpy()\n",
    "hourly_is_day = hourly.Variables(5).ValuesAsNumpy()\n",
    "hourly_sunshine_duration = hourly.Variables(6).ValuesAsNumpy()\n",
    "\n",
    "hourly_data = {\"date\": pd.date_range(\n",
    "\tstart = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
    "\tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
    "\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n",
    "\tinclusive = \"left\"\n",
    ")}\n",
    "hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n",
    "hourly_data[\"cloud_cover\"] = hourly_cloud_cover\n",
    "hourly_data[\"shortwave_radiation\"] = hourly_shortwave_radiation\n",
    "hourly_data[\"diffuse_radiation\"] = hourly_diffuse_radiation\n",
    "hourly_data[\"direct_normal_irradiance\"] = hourly_direct_normal_irradiance\n",
    "hourly_data[\"is_day\"] = hourly_is_day\n",
    "hourly_data[\"sunshine_duration\"] = hourly_sunshine_duration\n",
    "\n",
    "hourly_dataframe = pd.DataFrame(data = hourly_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourly_dataframe.info()\n",
    "# hourly_dataframe.describe()\n",
    "# hourly_dataframe.plot(x = \"date\", y = \"temperature_2m\")\n",
    "# hourly_dataframe.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with solar_ts\n",
    "energy_ts = solar_ts.merge(hourly_dataframe, on='date', how='inner')\n",
    "energy_ts.drop(columns=['is_day', 'sunshine_duration'], inplace=True)\n",
    "# energy_ts.info()\n",
    "# energy_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "train_ts = energy_ts[energy_ts[\"date\"] < \"2023-01-01\"]\n",
    "val_ts = energy_ts[(energy_ts[\"date\"] >= \"2023-01-01\") & (energy_ts[\"date\"] < \"2024-01-01\")]\n",
    "test_ts = energy_ts[energy_ts[\"date\"] >= \"2024-01-01\"]\n",
    "\n",
    "train_ts = train_ts.set_index(keys=\"date\", drop=True)\n",
    "val_ts = val_ts.set_index(keys=\"date\", drop=True)\n",
    "test_ts = test_ts.set_index(keys=\"date\", drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statioarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch train and val temporarily for testing to save memory\n",
    "train_ts = val_ts\n",
    "# train_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stationarity - Augmented Dicky Fuller Test\n",
    "def make_stationary(train_ts, val_ts, test_ts):\n",
    "    \"\"\"\n",
    "    Perform the Augmented Dickey-Fuller test on train_ts. If train_ts is not stationary,\n",
    "    difference train_ts, val_ts, and test_ts based on the train_ts result.\n",
    "    \n",
    "    Parameters:\n",
    "    train_ts (pd.DataFrame): The training time series data.\n",
    "    val_ts (pd.DataFrame): The validation time series data.\n",
    "    test_ts (pd.DataFrame): The test time series data.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    def perform_adf(series, column_name):\n",
    "        result = adfuller(series, autolag='AIC')\n",
    "        print(f'ADF Statistic for {column_name}: {result[0]}')\n",
    "        print(f'p-value for {column_name}: {result[1]}')\n",
    "        for key, value in result[4].items():\n",
    "            print(f'Critical Values for {column_name} {key}: {value}')\n",
    "        return result[1] < 0.05  # Return True if the series is stationary\n",
    "\n",
    "    def check_and_difference(series, column_name):\n",
    "        differenced = False\n",
    "        is_stationary = perform_adf(series, column_name)\n",
    "        iteration = 0\n",
    "        while not is_stationary:\n",
    "            print(f'The time series {column_name} is not stationary. Differencing the series and re-testing...')\n",
    "            series = series.diff().dropna()\n",
    "            is_stationary = perform_adf(series, f'{column_name} (Differenced {iteration+1})')\n",
    "            differenced = True\n",
    "            iteration += 1\n",
    "        \n",
    "        if is_stationary:\n",
    "            print(f'The time series {column_name} is stationary after differencing {iteration} time(s).')\n",
    "        else:\n",
    "            print(f'The time series {column_name} is still not stationary after differencing {iteration} time(s).')\n",
    "        \n",
    "        return series, differenced\n",
    "\n",
    "    for col in train_ts.columns:\n",
    "        print(f'Checking stationarity for {col}')\n",
    "        train_ts[col], differenced = check_and_difference(train_ts[col], col)\n",
    "        if differenced:\n",
    "            val_ts[col] = val_ts[col].diff().dropna()\n",
    "            test_ts[col] = test_ts[col].diff().dropna()\n",
    "        print(\"\\n\")  # Add a space between outputs\n",
    "\n",
    "# Iterate over each column and perform the combined ADF test\n",
    "make_stationary(train_ts, val_ts, test_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and decompose each time series as grid of plots\n",
    "for column in train_ts.columns:\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(10, 10))\n",
    "    axes[0].set_title(f\"{column} Time Series\")\n",
    "    train_ts[column].plot(ax=axes[0])\n",
    "    axes[0].set_ylabel(\"Value\")\n",
    "    axes[0].set_xlabel(\"Date\")\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    decomposition = seasonal_decompose(train_ts[column], model='additive', period=24)\n",
    "    decomposition.trend.plot(ax=axes[1])\n",
    "    axes[1].set_title(f\"{column} Trend\")\n",
    "    axes[1].set_ylabel(\"Value\")\n",
    "    axes[1].set_xlabel(\"Date\")\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    decomposition.seasonal.plot(ax=axes[2])\n",
    "    axes[2].set_title(f\"{column} Seasonal\")\n",
    "    axes[2].set_ylabel(\"Value\")\n",
    "    axes[2].set_xlabel(\"Date\")\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    decomposition.resid.plot(ax=axes[3])\n",
    "    axes[3].set_title(f\"{column} Residual\")\n",
    "    axes[3].set_ylabel(\"Value\")\n",
    "    axes[3].set_xlabel(\"Date\")\n",
    "    axes[3].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Test ACF and PACF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check autocorrelation of each series in the training data and display as grid\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "for col in train_ts.columns:\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    plot_acf(train_ts[col], ax=ax[0], lags=50, title=f'Autocorrelation of {col}')\n",
    "    plot_pacf(train_ts[col], ax=ax[1], lags=50, title=f'Partial Autocorrelation of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTIVARIATE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plots (pairwise)\n",
    "sns.pairplot(train_ts, diag_kind=\"kde\")  \n",
    "plt.show() \n",
    "\n",
    "# Sort features based on target variable correlation (absolute value)\n",
    "sorted_features = train_ts.corr().iloc[0,:].abs().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "# Ordered heatmap \n",
    "corr_matrix = train_ts[sorted_features].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"twilight\")  \n",
    "plt.show()\n",
    "\n",
    "# Correlation Matrix\n",
    "print(corr_matrix.to_string())  # Print the correlation matrix as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Granger Causality Tests for the series in train_ts\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "for col in train_ts.columns:\n",
    "    for col2 in train_ts.columns:\n",
    "        if col != col2:\n",
    "            print(f'Granger Causality Test for {col} and {col2}')\n",
    "            data = pd.concat([train_ts[col], train_ts[col2]], axis=1)\n",
    "            max_lag = 12\n",
    "            results = grangercausalitytests(data, max_lag, verbose=True)\n",
    "            print(\"\\n\")  # Add a space between outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline tbd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solar_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
