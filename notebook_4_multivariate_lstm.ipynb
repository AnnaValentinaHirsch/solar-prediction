{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!pip install numpy pandas matplotlib timeseriesfcst tensorflow"
   ],
   "id": "cdafa71ba3ae42ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup\n",
   "id": "f19845a328dd0c00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T14:59:35.715054Z",
     "start_time": "2024-07-29T14:59:35.705599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import timeseriesfcst.preprocessing as tsprep\n",
    "import timeseriesfcst.lstm as tslstm\n",
    "import timeseriesfcst.evaluation as eval\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam"
   ],
   "id": "96a874728f6d5ff",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define Constants\n",
   "id": "883e7d55c7812661"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T14:59:39.140921Z",
     "start_time": "2024-07-29T14:59:39.127940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "REPO_PATH = \"hf://datasets/Creatorin/solarpower/\"\n",
    "REPO_PATH_SELECTED = \"hf://datasets/Creatorin/solar_selected/\"\n",
    "REPO_PATH_PCA = \"hf://datasets/Creatorin/solar_pca/\"\n",
    "\n",
    "SEQUENCE_LENGTH = 24\n",
    "BATCH_SIZE = 8\n",
    "TARGET_COLUMN = 'Leistung'\n",
    "NUM_EPOCHS = 100\n",
    "OPTIMIZER = Adam(learning_rate=0.0001)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ],
   "id": "4c375a7f369f6730",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Data from Huggingface\n",
   "id": "699057030834951a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:00:38.680403Z",
     "start_time": "2024-07-29T14:59:41.719470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Original Dataset (No Feature Engineering)\n",
    "splits = {'train': 'train_ts.csv', 'validation': 'val_ts.csv', 'test': 'test_ts.csv'}\n",
    "\n",
    "train_ts = pd.read_csv(REPO_PATH + splits[\"train\"], index_col=0, date_format=\"%Y-%m-%d %H:%M:%S\")\n",
    "val_ts = pd.read_csv(REPO_PATH + splits[\"validation\"], index_col=0, date_format=\"%Y-%m-%d %H:%M:%S\")\n",
    "test_ts = pd.read_csv(REPO_PATH + splits[\"test\"], index_col=0, date_format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "# Dataset with Selected Features\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'validation': 'data/validation-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "\n",
    "train_selected = pd.read_parquet(REPO_PATH_SELECTED + splits[\"train\"])\n",
    "val_selected = pd.read_parquet(REPO_PATH_SELECTED + splits[\"validation\"])\n",
    "test_selected = pd.read_parquet(REPO_PATH_SELECTED + splits[\"test\"])\n",
    "\n",
    "# set index\n",
    "train_selected.set_index(\"__index_level_0__\", inplace=True)\n",
    "val_selected.set_index(\"__index_level_0__\", inplace=True)\n",
    "test_selected.set_index(\"__index_level_0__\", inplace=True)\n",
    "\n",
    "# Datetime\n",
    "train_selected.index = pd.to_datetime(train_selected.index)\n",
    "val_selected.index = pd.to_datetime(val_selected.index)\n",
    "test_selected.index = pd.to_datetime(test_selected.index)\n",
    "\n",
    "# PCA Dataset\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'validation': 'data/validation-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "\n",
    "train_pca = pd.read_parquet(\"hf://datasets/Creatorin/solar_pca/\" + splits[\"train\"])\n",
    "val_pca = pd.read_parquet(\"hf://datasets/Creatorin/solar_pca/\" + splits[\"validation\"])\n",
    "test_pca = pd.read_parquet(\"hf://datasets/Creatorin/solar_pca/\" + splits[\"test\"])\n",
    "\n",
    "# set index\n",
    "train_pca.set_index(\"__index_level_0__\", inplace=True)\n",
    "val_pca.set_index(\"__index_level_0__\", inplace=True)\n",
    "test_pca.set_index(\"__index_level_0__\", inplace=True)\n",
    "\n",
    "# Datetime\n",
    "train_pca.index = pd.to_datetime(train_pca.index)\n",
    "val_pca.index = pd.to_datetime(val_pca.index)\n",
    "test_pca.index = pd.to_datetime(test_pca.index)\n",
    "\n",
    "# Confirm Shapes\n",
    "print(f\"Train Shape Original: {train_ts.shape}, Validation Shape: {val_ts.shape}, Test Shape: {test_ts.shape}\")\n",
    "print(f\"Train Shape Selected: {train_selected.shape}, Validation Shape: {val_selected.shape}, Test Shape: {test_selected.shape}\")\n",
    "print(f\"Train Shape PCA: {train_pca.shape}, Validation Shape: {val_pca.shape}, Test Shape: {test_pca.shape}\")"
   ],
   "id": "f56b704c89214c66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape Original: (70129, 31), Validation Shape: (8760, 31), Test Shape: (2926, 31)\n",
      "Train Shape Selected: (61368, 50), Validation Shape: (8759, 50), Test Shape: (2925, 50)\n",
      "Train Shape PCA: (61368, 617), Validation Shape: (8759, 617), Test Shape: (2925, 617)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verify Dates\n",
    "print(train_ts.index.min())\n",
    "print(train_ts.index.max())\n",
    "\n",
    "print(train_selected.index.min())\n",
    "print(train_selected.index.max())\n",
    "\n",
    "print(train_pca.index.min())\n",
    "print(train_pca.index.max())"
   ],
   "id": "aaba451ebe4ef002",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare Data for LSTM\n",
   "id": "ad403d343aadb770"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:00:38.755500Z",
     "start_time": "2024-07-29T15:00:38.687650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Normalise original dataset (the others are already normalised)\n",
    "train_ts, val_ts, test_ts = tsprep.normalise_ts(train_ts, val_ts, test_ts)"
   ],
   "id": "ba756f06c4f52815",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T15:00:46.044291Z",
     "start_time": "2024-07-29T15:00:38.760824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Sequences\n",
    "X_train, y_train = tslstm.create_sequences(train_ts, TARGET_COLUMN, SEQUENCE_LENGTH, BATCH_SIZE)\n",
    "X_val, y_val = tslstm.create_sequences(val_ts, TARGET_COLUMN, SEQUENCE_LENGTH, BATCH_SIZE)\n",
    "X_test, y_test = tslstm.create_sequences(test_ts, TARGET_COLUMN, SEQUENCE_LENGTH, BATCH_SIZE)\n",
    "\n",
    "# Create Sequences for selected features\n",
    "X_train_selected, y_train_selected = tslstm.create_sequences(train_selected, TARGET_COLUMN, SEQUENCE_LENGTH, BATCH_SIZE)\n",
    "X_val_selected, y_val_selected = tslstm.create_sequences(val_selected, TARGET_COLUMN, SEQUENCE_LENGTH, BATCH_SIZE)\n",
    "X_test_selected, y_test_selected = tslstm.create_sequences(test_selected, TARGET_COLUMN, SEQUENCE_LENGTH, BATCH_SIZE)\n",
    "\n",
    "# Create Sequences for PCA features\n",
    "X_train_pca, y_train_pca = tslstm.create_sequences(train_pca, TARGET_COLUMN, SEQUENCE_LENGTH, BATCH_SIZE)\n",
    "X_val_pca, y_val_pca = tslstm.create_sequences(val_pca, TARGET_COLUMN, SEQUENCE_LENGTH, BATCH_SIZE)\n",
    "X_test_pca, y_test_pca = tslstm.create_sequences(test_pca, TARGET_COLUMN, SEQUENCE_LENGTH, BATCH_SIZE)\n",
    "\n",
    "# Print the shapes\n",
    "print(\"Training set - X shape:\", X_train.shape, \"y shape:\", y_train.shape)\n",
    "print(\"Validation set - X shape:\", X_val.shape, \"y shape:\", y_val.shape)\n",
    "print(\"Test set - X shape:\", X_test.shape, \"y shape:\", y_test.shape)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training set selected - X shape:\", X_train_selected.shape, \"y shape:\", y_train_selected.shape)\n",
    "print(\"Validation set selected - X shape:\", X_val_selected.shape, \"y shape:\", y_val_selected.shape)\n",
    "print(\"Test set selected - X shape:\", X_test_selected.shape, \"y shape:\", y_test_selected.shape)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training set pca - X shape:\", X_train_pca.shape, \"y shape:\", train_pca.shape)\n",
    "print(\"Validation set pca - X shape:\", X_val_pca.shape, \"y shape:\", y_val_pca.shape)\n",
    "print(\"Test set pca - X shape:\", X_test_pca.shape, \"y shape:\", y_test_pca.shape)"
   ],
   "id": "94819c085e81021c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set - X shape: (70105, 3, 31) y shape: (70105,)\n",
      "Validation set - X shape: (8736, 3, 31) y shape: (8736,)\n",
      "Test set - X shape: (2902, 3, 31) y shape: (2902,)\n",
      "\n",
      "Training set selected - X shape: (61344, 3, 50) y shape: (61344,)\n",
      "Validation set selected - X shape: (8735, 3, 50) y shape: (8735,)\n",
      "Test set selected - X shape: (2901, 3, 50) y shape: (2901,)\n",
      "\n",
      "Training set pca - X shape: (61344, 3, 617) y shape: (61368, 617)\n",
      "Validation set pca - X shape: (8735, 3, 617) y shape: (8735,)\n",
      "Test set pca - X shape: (2901, 3, 617) y shape: (2901,)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LSTM with Original Dataset\n",
    "## Train"
   ],
   "id": "71545b1061a3d591"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-29T15:00:46.048511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "model = tslstm.create_lstm_model(input_shape, optimizer=OPTIMIZER)\n",
    "\n",
    "# Train the model\n",
    "history = tslstm.train_lstm_model(\n",
    "    model, X_train, y_train, X_val, y_val, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Plot train val losses\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss Original Dataset')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ],
   "id": "1ea31e61951040af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moonchild/PycharmProjects/solar-prediction/solarvenv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m7199/8764\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m10s\u001B[0m 7ms/step - loss: 0.2556"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Predict",
   "id": "f13daa2c3e3f4ca8"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Plot predictions \n",
    "plt.plot(figsize=(10, 6))\n",
    "plt.plot(y_test, label='True')\n",
    "plt.plot(predictions, label='Predicted')\n",
    "plt.title('Predictions Original Dataset')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Get performance metrics\n",
    "metrics = eval.evaluate_model(y_test, predictions)\n",
    "print(metrics)"
   ],
   "id": "474a948773a27455",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "\n",
   "id": "7e11462c853b21e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Importance\n",
   "id": "f05c33a70397b865"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate permutation importance\n",
    "importances = eval.permutation_importance(model, X_test, y_test)\n",
    "\n",
    "# get feature names (column names)\n",
    "feature_names = train_ts.columns\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance (Increase in MSE)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print feature importance\n",
    "print(importance_df)"
   ],
   "id": "8a99d3e203dc59cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LSTM with Selected Features\n",
    "## Train"
   ],
   "id": "c4f7dacccf2e057b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the model\n",
    "input_shape = (X_train_selected.shape[1], X_train_selected.shape[2])\n",
    "model = tslstm.create_lstm_model(input_shape)\n",
    "\n",
    "# Train the model\n",
    "history = tslstm.train_lstm_model(\n",
    "    model, X_train_selected, y_train_selected, X_val_selected, y_val_selected, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss = model.evaluate(X_test_selected, y_test_selected, verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Plot train val losses\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss Selected Features')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ],
   "id": "ccb6cb29337a5e20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Predict\n",
   "id": "f044b18cce026a03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test_selected)\n",
    "\n",
    "# Plot predictions\n",
    "plt.plot(figsize=(10, 6))\n",
    "plt.plot(y_test_selected, label='True')\n",
    "plt.plot(predictions, label='Predicted')\n",
    "plt.title('Predictions Selected Features')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Get performance metrics\n",
    "metrics = eval.evaluate_model(y_test_selected, predictions)\n",
    "print(metrics)"
   ],
   "id": "ab2c087f4496f629",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LSTM with PCA Features\n",
    "## Train"
   ],
   "id": "198981c5f359be7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c1ec232608a7fad3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the model\n",
    "input_shape = (X_train_pca.shape[1], X_train_pca.shape[2])\n",
    "model = tslstm.create_lstm_model(input_shape)\n",
    "\n",
    "# Train the model\n",
    "history = tslstm.train_lstm_model(\n",
    "    model, X_train_pca, y_train_pca, X_val_pca, y_val_pca, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss = model.evaluate(X_test_pca, y_test_pca, verbose=0)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Plot train val losses\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss PCA Features')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ],
   "id": "714762352e00104d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Predict",
   "id": "b55d38223e6e4219"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test_pca)\n",
    "\n",
    "# Get performance metrics\n",
    "metrics = eval.evaluate_model(y_test_pca, predictions)\n",
    "print(metrics)\n",
    "\n",
    "# Plot predictions\n",
    "plt.plot(figsize=(10, 6))\n",
    "plt.plot(y_test_pca, label='True')\n",
    "plt.plot(predictions, label='Predicted')\n",
    "plt.title('Predictions PCA Features')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "c50d484eaca73581",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a1e233739a5e46a6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
